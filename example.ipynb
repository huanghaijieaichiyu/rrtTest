{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络增强 RRT 算法教程\n",
    "\n",
    "本教程展示如何使用神经网络增强 RRT 算法进行路径规划。主要内容包括：\n",
    "\n",
    "1. 环境准备和依赖安装\n",
    "2. 训练数据生成和预处理\n",
    "3. 神经网络模型训练\n",
    "4. 使用训练好的模型进行路径规划\n",
    "5. 基于 Pygame 的可视化演示\n",
    "\n",
    "## 环境准备\n",
    "\n",
    "首先确保已安装所需的依赖包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch numpy pygame matplotlib tqdm shapely pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入必要的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 添加项目根目录到 Python 路径\n",
    "current_dir = os.path.dirname(os.path.abspath('.'))\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "from ml.data import DataGenerator, create_data_loaders, RRTDataset\n",
    "from ml.models.rrt_nn import NeuralRRT, SamplingNetwork, EvaluationNetwork, OptimizationNetwork\n",
    "from simulation.environment import Environment\n",
    "from rrt.rrt_star import RRTStar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 训练数据准备\n",
    "\n",
    "### 2.1 加载已生成的训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未找到预生成的数据集，将创建新的数据集\n",
      "数据生成器初始化完成\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     23\u001b[0m examples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m生成训练样本\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(examples) \u001b[38;5;241m<\u001b[39m num_examples:\n\u001b[0;32m     27\u001b[0m         example \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mgenerate_example()\n",
      "File \u001b[1;32md:\\conda\\envs\\rrtCarsim\\lib\\site-packages\\tqdm\\notebook.py:238\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    237\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\rrtCarsim\\lib\\site-packages\\tqdm\\notebook.py:113\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    115\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# 加载已生成的训练数据\n",
    "data_path = os.path.join(current_dir, 'data/training/rrt_dataset.pt')\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    dataset = torch.load(data_path)\n",
    "    print(f\"成功加载数据集，样本数量: {len(dataset)}\")\n",
    "else:\n",
    "    print(\"未找到预生成的数据集，将创建新的数据集\")\n",
    "    # 配置数据生成器参数\n",
    "    generator = DataGenerator(\n",
    "        env_width=500.0,\n",
    "        env_height=300.0,\n",
    "        grid_size=(64, 64),\n",
    "        min_obstacles=3,\n",
    "        max_obstacles=8,\n",
    "        num_samples=100\n",
    "    )\n",
    "    \n",
    "    print(\"数据生成器初始化完成\")\n",
    "    \n",
    "    # 生成训练样本\n",
    "    num_examples = 10\n",
    "    examples = []\n",
    "    \n",
    "    with tqdm(total=num_examples, desc=\"生成训练样本\") as pbar:\n",
    "        while len(examples) < num_examples:\n",
    "            example = generator.generate_example()\n",
    "            if example is not None:\n",
    "                examples.append(example)\n",
    "                pbar.update(1)\n",
    "    \n",
    "    # 创建数据集\n",
    "    dataset = generator.generate_dataset(examples)\n",
    "    \n",
    "    # 保存数据集\n",
    "    os.makedirs(os.path.dirname(data_path), exist_ok=True)\n",
    "    torch.save(dataset, data_path)\n",
    "    print(f\"数据集已保存到 {data_path}\")\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader, val_loader = create_data_loaders(\n",
    "    dataset,\n",
    "    batch_size=2,  # 使用小批量以适应小数据集\n",
    "    train_ratio=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 查看数据集统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_stats(dataset):\n",
    "    \"\"\"打印数据集统计信息\"\"\"\n",
    "    print(\"\\n数据集统计信息:\")\n",
    "    print(f\"样本数量: {len(dataset)}\")\n",
    "    \n",
    "    # 计算路径长度统计\n",
    "    path_lengths = [ex.path_length for ex in dataset.examples]\n",
    "    print(\"\\n路径长度统计:\")\n",
    "    print(f\"  最小值: {min(path_lengths):.2f}\")\n",
    "    print(f\"  最大值: {max(path_lengths):.2f}\")\n",
    "    print(f\"  平均值: {np.mean(path_lengths):.2f}\")\n",
    "    print(f\"  标准差: {np.std(path_lengths):.2f}\")\n",
    "    \n",
    "    # 计算平滑度统计\n",
    "    smoothness = [ex.smoothness for ex in dataset.examples]\n",
    "    print(\"\\n平滑度统计:\")\n",
    "    print(f\"  最小值: {min(smoothness):.2f}\")\n",
    "    print(f\"  最大值: {max(smoothness):.2f}\")\n",
    "    print(f\"  平均值: {np.mean(smoothness):.2f}\")\n",
    "    print(f\"  标准差: {np.std(smoothness):.2f}\")\n",
    "    \n",
    "    # 计算间隙统计\n",
    "    clearance = [ex.clearance for ex in dataset.examples]\n",
    "    print(\"\\n障碍物间隙统计:\")\n",
    "    print(f\"  最小值: {min(clearance):.2f}\")\n",
    "    print(f\"  最大值: {max(clearance):.2f}\")\n",
    "    print(f\"  平均值: {np.mean(clearance):.2f}\")\n",
    "    print(f\"  标准差: {np.std(clearance):.2f}\")\n",
    "\n",
    "print_dataset_stats(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 可视化训练样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 可视化一个训练样本\n",
    "def visualize_sample(example, index=0):\n",
    "    # 创建环境\n",
    "    env = Environment(width=500.0, height=300.0)\n",
    "    \n",
    "    # 添加障碍物\n",
    "    for obs_dict in example.obstacles:\n",
    "        if obs_dict['type'] == 'circle':\n",
    "            env.add_obstacle(\n",
    "                x=obs_dict['x'],\n",
    "                y=obs_dict['y'],\n",
    "                obstacle_type='circle',\n",
    "                radius=obs_dict['radius']\n",
    "            )\n",
    "        elif obs_dict['type'] == 'rectangle':\n",
    "            env.add_obstacle(\n",
    "                x=obs_dict['x'],\n",
    "                y=obs_dict['y'],\n",
    "                obstacle_type='rectangle',\n",
    "                width=obs_dict['width'],\n",
    "                height=obs_dict['height'],\n",
    "                angle=obs_dict['angle']\n",
    "            )\n",
    "    \n",
    "    # 可视化环境和路径\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    env.plot_obstacles(ax)\n",
    "    \n",
    "    # 绘制起点和终点\n",
    "    ax.plot(example.start[0], example.start[1], 'go', markersize=10, label='起点')\n",
    "    ax.plot(example.goal[0], example.goal[1], 'ro', markersize=10, label='终点')\n",
    "    \n",
    "    # 绘制路径\n",
    "    path_x = [p[0] for p in example.path]\n",
    "    path_y = [p[1] for p in example.path]\n",
    "    ax.plot(path_x, path_y, 'b-', linewidth=2, label='路径')\n",
    "    \n",
    "    # 绘制采样点\n",
    "    valid_x = [p[0] for p in example.valid_samples[:100]]  # 限制点数以避免过度绘制\n",
    "    valid_y = [p[1] for p in example.valid_samples[:100]]\n",
    "    ax.scatter(valid_x, valid_y, c='g', s=2, alpha=0.3, label='有效采样点')\n",
    "    \n",
    "    invalid_x = [p[0] for p in example.invalid_samples[:100]]\n",
    "    invalid_y = [p[1] for p in example.invalid_samples[:100]]\n",
    "    ax.scatter(invalid_x, invalid_y, c='r', s=2, alpha=0.3, label='无效采样点')\n",
    "    \n",
    "    # 设置图表\n",
    "    ax.set_xlim(0, 500)\n",
    "    ax.set_ylim(0, 300)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.legend()\n",
    "    ax.set_title(f'训练样本 #{index+1}')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # 打印样本信息\n",
    "    print(f\"样本 #{index+1} 信息:\")\n",
    "    print(f\"  路径长度: {example.path_length:.2f}\")\n",
    "    print(f\"  平滑度: {example.smoothness:.2f}\")\n",
    "    print(f\"  障碍物间隙: {example.clearance:.2f}\")\n",
    "    print(f\"  路径点数: {len(example.path)}\")\n",
    "    print(f\"  有效采样点数: {len(example.valid_samples)}\")\n",
    "    print(f\"  无效采样点数: {len(example.invalid_samples)}\")\n",
    "\n",
    "# 可视化第一个样本\n",
    "visualize_sample(dataset.examples[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型训练\n",
    "\n",
    "### 3.1 初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 初始化神经网络\n",
    "sampling_net = SamplingNetwork().to(device)\n",
    "evaluation_net = EvaluationNetwork().to(device)\n",
    "optimization_net = OptimizationNetwork().to(device)\n",
    "\n",
    "# 创建优化器\n",
    "learning_rate = 1e-3\n",
    "optimizers = {\n",
    "    'sampling': torch.optim.Adam(sampling_net.parameters(), lr=learning_rate),\n",
    "    'evaluation': torch.optim.Adam(evaluation_net.parameters(), lr=learning_rate),\n",
    "    'optimization': torch.optim.Adam(optimization_net.parameters(), lr=learning_rate)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 训练模型\n",
    "\n",
    "注意：由于我们的数据集很小，这里只进行少量训练，主要是为了演示流程。实际应用中应该使用更大的数据集和更多的训练轮次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10  # 使用较少的轮次以快速演示\n",
    "save_dir = 'results/models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练模式\n",
    "    sampling_net.train()\n",
    "    evaluation_net.train()\n",
    "    optimization_net.train()\n",
    "    \n",
    "    train_loss = {'sampling': 0.0, 'evaluation': 0.0, 'optimization': 0.0}\n",
    "    \n",
    "    with tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}') as pbar:\n",
    "        for batch in pbar:\n",
    "            # 将数据移到设备上\n",
    "            env_state = batch['env_state'].to(device)\n",
    "            start = batch['start'].to(device)\n",
    "            goal = batch['goal'].to(device)\n",
    "            path = batch['path'].to(device)\n",
    "            \n",
    "            # 训练采样网络\n",
    "            optimizers['sampling'].zero_grad()\n",
    "            sample_loss = sampling_net.compute_loss(env_state, start, goal)\n",
    "            sample_loss.backward()\n",
    "            optimizers['sampling'].step()\n",
    "            \n",
    "            # 训练评估网络\n",
    "            optimizers['evaluation'].zero_grad()\n",
    "            eval_loss = evaluation_net.compute_loss(env_state, path)\n",
    "            eval_loss.backward()\n",
    "            optimizers['evaluation'].step()\n",
    "            \n",
    "            # 训练优化网络\n",
    "            optimizers['optimization'].zero_grad()\n",
    "            opt_loss = optimization_net.compute_loss(env_state, path)\n",
    "            opt_loss.backward()\n",
    "            optimizers['optimization'].step()\n",
    "            \n",
    "            # 更新损失\n",
    "            train_loss['sampling'] += sample_loss.item()\n",
    "            train_loss['evaluation'] += eval_loss.item()\n",
    "            train_loss['optimization'] += opt_loss.item()\n",
    "            \n",
    "            # 更新进度条\n",
    "            pbar.set_postfix({\n",
    "                'sample_loss': sample_loss.item(),\n",
    "                'eval_loss': eval_loss.item(),\n",
    "                'opt_loss': opt_loss.item()\n",
    "            })\n",
    "    \n",
    "    # 打印每个 epoch 的平均损失\n",
    "    print(f\"\\nEpoch {epoch+1} 平均损失:\")\n",
    "    for key, value in train_loss.items():\n",
    "        print(f\"  {key}: {value/len(train_loader):.4f}\")\n",
    "    \n",
    "    # 保存模型\n",
    "    if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:\n",
    "        torch.save(sampling_net.state_dict(), f\"{save_dir}/sampling_net_epoch_{epoch+1}.pt\")\n",
    "        torch.save(evaluation_net.state_dict(), f\"{save_dir}/evaluation_net_epoch_{epoch+1}.pt\")\n",
    "        torch.save(optimization_net.state_dict(), f\"{save_dir}/optimization_net_epoch_{epoch+1}.pt\")\n",
    "        print(f\"模型已保存到 {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 使用训练好的模型进行路径规划\n",
    "\n",
    "### 4.1 创建测试环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建测试环境\n",
    "test_env = Environment(width=500.0, height=300.0)\n",
    "\n",
    "# 添加一些障碍物\n",
    "test_env.add_obstacle(x=150, y=150, obstacle_type=\"circle\", radius=30)\n",
    "test_env.add_obstacle(x=300, y=100, obstacle_type=\"rectangle\", width=50, height=40)\n",
    "test_env.add_obstacle(x=250, y=200, obstacle_type=\"circle\", radius=25)\n",
    "\n",
    "# 设置起点和终点\n",
    "start_point = (50, 50)\n",
    "goal_point = (450, 250)\n",
    "\n",
    "# 可视化环境\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "test_env.plot_obstacles(ax)\n",
    "ax.plot(start_point[0], start_point[1], 'go', markersize=10, label='起点')\n",
    "ax.plot(goal_point[0], goal_point[1], 'ro', markersize=10, label='终点')\n",
    "ax.set_xlim(0, 500)\n",
    "ax.set_ylim(0, 300)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend()\n",
    "ax.set_title('测试环境')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 使用神经网络增强的 RRT 进行路径规划"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建神经网络增强的 RRT 规划器\n",
    "neural_rrt = NeuralRRT(\n",
    "    sampling_net=sampling_net,\n",
    "    evaluation_net=evaluation_net,\n",
    "    optimization_net=optimization_net,\n",
    "    start=start_point,\n",
    "    goal=goal_point,\n",
    "    env=test_env,\n",
    "    max_iterations=1000\n",
    ")\n",
    "\n",
    "# 进行路径规划\n",
    "path = neural_rrt.plan()\n",
    "\n",
    "if path:\n",
    "    print(\"路径规划成功!\")\n",
    "    # 可视化规划结果\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    test_env.plot_obstacles(ax)\n",
    "    ax.plot(start_point[0], start_point[1], 'go', markersize=10, label='起点')\n",
    "    ax.plot(goal_point[0], goal_point[1], 'ro', markersize=10, label='终点')\n",
    "    \n",
    "    # 绘制路径\n",
    "    path_x = [p[0] for p in path]\n",
    "    path_y = [p[1] for p in path]\n",
    "    ax.plot(path_x, path_y, 'b-', linewidth=2, label='神经网络增强 RRT 路径')\n",
    "    \n",
    "    ax.set_xlim(0, 500)\n",
    "    ax.set_ylim(0, 300)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.legend()\n",
    "    ax.set_title('神经网络增强 RRT 路径规划结果')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"未找到有效路径\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 与传统 RRT* 算法对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用传统 RRT* 进行规划\n",
    "rrt_star = RRTStar(\n",
    "    start=start_point,\n",
    "    goal=goal_point,\n",
    "    env=test_env,\n",
    "    max_iterations=1000,\n",
    "    step_size=10.0,\n",
    "    goal_sample_rate=0.2\n",
    ")\n",
    "\n",
    "rrt_path = rrt_star.plan()\n",
    "\n",
    "if rrt_path:\n",
    "    print(\"RRT* 规划成功!\")\n",
    "    # 可视化规划结果\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    test_env.plot_obstacles(ax)\n",
    "    ax.plot(start_point[0], start_point[1], 'go', markersize=10, label='起点')\n",
    "    ax.plot(goal_point[0], goal_point[1], 'ro', markersize=10, label='终点')\n",
    "    \n",
    "    # 绘制路径\n",
    "    path_x = [p[0] for p in rrt_path]\n",
    "    path_y = [p[1] for p in rrt_path]\n",
    "    ax.plot(path_x, path_y, 'g-', linewidth=2, label='RRT* 路径')\n",
    "    \n",
    "    ax.set_xlim(0, 500)\n",
    "    ax.set_ylim(0, 300)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.legend()\n",
    "    ax.set_title('RRT* 路径规划结果')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"RRT* 未找到有效路径\")\n",
    "\n",
    "# 比较路径质量\n",
    "if path and rrt_path:\n",
    "    neural_length = sum(np.linalg.norm(np.array(path[i+1]) - np.array(path[i])) \n",
    "                       for i in range(len(path)-1))\n",
    "    rrt_length = sum(np.linalg.norm(np.array(rrt_path[i+1]) - np.array(rrt_path[i])) \n",
    "                     for i in range(len(rrt_path)-1))\n",
    "    \n",
    "    print(f\"\\n路径长度对比:\")\n",
    "    print(f\"神经网络增强 RRT: {neural_length:.2f}\")\n",
    "    print(f\"传统 RRT*: {rrt_length:.2f}\")\n",
    "    print(f\"改进比例: {((rrt_length - neural_length) / rrt_length * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 总结\n",
    "\n",
    "本教程展示了如何：\n",
    "\n",
    "1. 准备训练数据\n",
    "2. 训练神经网络模型\n",
    "3. 使用训练好的模型进行路径规划\n",
    "4. 与传统 RRT* 算法进行对比\n",
    "\n",
    "神经网络增强的 RRT 算法通过学习环境特征和历史规划经验，可以：\n",
    "\n",
    "- 生成更智能的采样策略\n",
    "- 更准确地评估路径质量\n",
    "- 优化生成的路径\n",
    "\n",
    "这些改进使得算法能够更快地找到更优质的路径。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rrtCarsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
